假设用 P 来评估计算机程序在某任务类 T 上的性能,若一个程序通过利用经验 E 在 T 中任务上获得了性能改善,则我们就说关于 T 和 P,该程序对 E 进行了学习.

数据集(data set)是记录的集合,每条记录是关于一个事件或对象的描述,称为一个示例(instance)或样本(sample).反映事件或对象在某方面的表现或性质的事项称为属性(attribute)或特征(feature),属性的取值称为属性值(attribute value).属性张成的空间称为属性空间(attribute space),样本空间(sample space)或输入空间.由于空间的每一个点对应一个坐标向量,一个示例可以称为一个特征向量(feature vector).

一般地,令 D = {x1, x2, ..., xm}表示含m个示例的数据集,每个示例由 d 个属性描述,每个示例 xi = (xi1; xi2; ...; xid)是 d 维样本空间 X 中的一个向量,xi ∈ X,其中xij是xi在第j个属性的取值, d 称为样本 xi 的位数(dimensionality).

从数据中学得模型的过程称为学习(learning)或训练(training),这个过程通过执行某个学习算法来完成.训练过程使用的数据称为训练数据(training data),其中每个样本称为一个训练样本(training sample),训练示例(training instance)或训练例,训练样本组成的集合称为训练集(training set).学得模型对应关于数据的某种潜在的规律,因此亦称假设(hypothesis);这种潜在规律称为真相或真实(ground-truth).模型又叫学习器(learner),可以看作学习算法在给定数据和参数空间的实例化.

关于示例结果的信息称为标记(label),拥有标记信息的示例称为样例(example).一般地,用(xi,yi)表示第i个样例,其中yi∈Y是示例xi的标记,Y是所有标记的集合,也称标记空间(label space)或输出空间.

将预测离散值的学习任务称为分类(classification),预测连续值的学习任务称为回归(regression).对于只涉及两个类别的二分类(binary classification)任务,通常称其中一个类为正类(positive class),另一个为反类(negative class)或负类;涉及多个类别时则称多分类(multi-class classification)任务.一般地,预测任务是希望通过对训练集进行学习,建立一个从输入空间到输出空间的映射.

学得模型后使用其进行预测的过程称为测试(testing),被预测的样本称为测试样本(testing sample),测试示例(testing instance)或测试例.

可以对示例做聚类(clustering),即将示例分组,每组称为一个簇(cluster).

根据训练数据是否拥有标记信息,学习任务可大致划分为两大类:监督学习(supervised learning)和无监督学习(unsupervised learning),分类和回归是前者的代表,聚类是后者的代表.

学得模型适用于新样本的能力称为泛化(generalization)能力.设样本空间中全体样本服从一个未知分布(distribution)D,获得的每个样本都是独立地从这个分布上采样获得的,即独立同分布(independent and identically distributed,简称i.i.d.).

归纳(induction)与演绎(deduction)相当于泛化(generalization)与特化(specialization),故从样例中学习也称归纳学习(inductive learning).

广义的归纳学习大体相当于从样例中学习,狭义的归纳学习则要求从训练数据中学得概念(concept),因此也称概念学习或概念形成.

学习过程可以看作一个在所有假设(hypothesis)组成的空间中进行搜索的过程,搜索的目标是找到与训练集匹配(fit)的假设.与训练集一致的假设集合称为版本空间(version space)

算法在学习过程中对某种类型假设的偏好称为归纳偏好(inductive bias)或简称偏好

无论学习算法笨拙与否,他们对正确结果的期望性能相同,称为没有免费的午餐定理(no free lunch theorem简称NFL),这意味着谈论算法优劣需要针对具体的学习问题.

# 第二章 模型评估与选择

将分类错误的样本数占总样本数的比例称为错误率(error rate).相应的精度(accuracy)是分类正确的样本数占总样本数的比例.学习器在实际预测输出与样本的真实输出之间的差异称为误差(error),学习器在训练集上的误差称为训练误差(training error)或经验误差(empirical error),在新样本上的误差称为泛化误差(generalization error),这里的误差均指误差期望.

当训练误差极小时有可能导致泛化能力下降,称为过拟合(overfitting).反之称为欠拟合(underfitting).

通过实验测试来评估学习器的泛化误差,需要一个测试集(testing set),将测试误差(testing error)近似为泛化误差.测试样本也应尽量满足独立同分布且与训练集互斥.

通过对数据集处理可以产出训练集和测试集:
法一:留出法(hold-out),即直接把数据集分成两个互斥的集合,一个训练集练出模型后用另一个测试集测试误差,作为对泛化误差的估计,一般测试集至少含30个样例并占样本的2/3~4/5且尽可能保持数据分布的一致性;
法二:交叉验证法(cross validation),即将数据集分成多个互斥子集,每次用一个子集做测试集,剩下的做训练集,并返回每一次测试结果的均值,视子集个数称交叉验证法为k折交叉验证(k-fold cross validation),k的常用取值是10,即10折交叉验证,其他常用取值有5,20等,为了减少因样本划分导致的差别需要随机使用不同划分重复p次,取折p次k折交叉验证结果的均值,常见有10折10次交叉验证,特别的当k取到数据集的样本数时,这种验证法叫做留一法(Leave-One-Out,简称LOO);
法三:自助法(bootstrapping)每次有放回地取出一个样本到一个新集合直到这个新集合的元素个数和数据集相等,把这个新集合做训练集,不在这个集合里的样本作为测试集.

学得模型在实际使用中遇到的数据称为测试数据,模型评估与选择中用于评估测试的数据集称为验证集(validation set)

对泛化能力的评价标准叫性能度量(performance measure),回归任务常用的性能度量是均方误差(mean squared error)
![[QQ_1723650372670.png]]

更一般的,对于数据分布D和概率密度函数p(·)均方误差可以描述为
![[QQ_1723650443717.png]]
错误率和精度是分类任务中最常用的两类性能度量,错误率是分类错误的样本数总样本数的比例,精度是分类正确的样本数占样本总数的比例.对样例集D,错误率为:
![[QQ_1723650556808 1.png]]
精度为:
![[QQ_1723650582852 1.png]]
更一般的,对于数据分布D和概率密度函数p(·),错误率和精度分别是:
![[QQ_1723650718292.png]]
![[QQ_1723650727768.png]]

对于二分类问题可以将样例根据真实类别和学习器预测类别的组合分为真正例(true positive),假正例(false positive),真反例(true negative),假反例(false negative)四种情形,令TP,FP,TN,FN分别表示对应的样例数,则TP+FP+TN+FN=样例总数.分类结果的混淆矩阵(confusion matrix)为:
![[QQ_1723651049290.png]]

查准率P与查全率R分别定义为
![[QQ_1723651072674.png]]
对样本集按从学习器认为最可能是正例的样本到学习器认为最不可能是正例的样本的顺序排序,按此顺序逐个把样本作为正例进行预测,每次可以得到当前的查全率,查准率.以查准率为纵轴,查全率为横轴作图可以得到查准率-查全率曲线,即"P-R曲线.P-R图可以直观显示学习器在样本总体上的查全率,查准率.进行比较时,若一个学习器的曲线完全被另一个学习器的曲线包住,则后者性能优于前者,如果有交叉则难以简单比较,比较合理的方法有计算曲线下面积,但是这个方法难计算,当查准率=查全率的取值平衡点(Break-Event Point,简称BEP)也是一个度量值,但是这个值过于简化,更常用F1度量:
![[QQ_1723908381236.png]]
这是基于查准率和查全率的调和平均定义的,他的一般形式Fβ:
![[QQ_1723908446465.png]]
可以用正数β与1的比例关系表达出对查准率和查全率的不同偏好.

对于多个二分类混淆矩阵考察查准率和查全率时一种直接的做法是分别计算查准率和查全率,再计算平均值,得到宏查准率(macro-P)和宏查全率(macro-R),再计算宏F1(macro-F1):
![[QQ_1723908658485.png]]
还可以先计算TP,FP,TN,FN的平均值然后再计算出微查准率(micro-P),微查准率(micro-R)和微F1(micro-F1)
![[QQ_1723911140480.png]]
![[QQ_1723911148535.png]]

许多学习器通过对样本产生预测值并与分类阈值(threshold)比较进行分类,将预测值排序就可以将分类问题转化为寻找截断点(cut point)问题.